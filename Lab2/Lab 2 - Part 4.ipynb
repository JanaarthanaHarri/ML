{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Lab 2 - Part 4 - Copy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1810146f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Masking, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost\n",
        "import gensim\n",
        "from gensim.models import Word2Vec,KeyedVectors\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import StratifiedKFold,KFold,StratifiedShuffleSplit\n",
        "import re,string,unicodedata\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk"
      ],
      "id": "1810146f",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w9kqlaQZze7",
        "outputId": "24040e95-edf3-4aab-b1f5-a894ec874497"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "id": "1w9kqlaQZze7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f74c521"
      },
      "source": [
        "##### 1. Download data from Lab 2 folder on Canvas."
      ],
      "id": "9f74c521"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bdf1c46"
      },
      "source": [
        "data = pd.read_csv(\"Part4_Dataset.csv\")"
      ],
      "id": "2bdf1c46",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39e1c04c",
        "outputId": "c9adac2d-dd6f-4b45-e224-2b6d353e7aa4"
      },
      "source": [
        "data.info()"
      ],
      "id": "39e1c04c",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ce0ae3b7",
        "outputId": "89a1c01d-e6ff-4fd6-fdae-b8bfb02ee8c4"
      },
      "source": [
        "data.head()"
      ],
      "id": "ce0ae3b7",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "e97405aa",
        "outputId": "2b98e54a-2c1e-4ae6-abf0-1e91915586db"
      },
      "source": [
        "data.describe().transpose()"
      ],
      "id": "e97405aa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review</th>\n",
              "      <td>50000</td>\n",
              "      <td>49582</td>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <td>50000</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count  ...   freq\n",
              "review     50000  ...      5\n",
              "sentiment  50000  ...  25000\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c944fd",
        "outputId": "f66e58c4-4c2f-4293-ab7c-9d61252a66a2"
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "id": "79c944fd",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7236496"
      },
      "source": [
        " - We see the data is balanced"
      ],
      "id": "a7236496"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68d458b1"
      },
      "source": [
        "df = data.copy()"
      ],
      "id": "68d458b1",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "4edf35d8",
        "outputId": "b3e65154-5090-4e18-82c3-3ecd4b50a343"
      },
      "source": [
        "df['review'][1]"
      ],
      "id": "4edf35d8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "b112dd30",
        "outputId": "807f382f-adef-476d-c9d2-d29d4641422a"
      },
      "source": [
        "# converting the sentiments to binary for reference\n",
        "\n",
        "train_li=[]\n",
        "for i in range(len(df)):\n",
        "    if (df['sentiment'][i]=='positive'):\n",
        "        train_li.append(1)\n",
        "    else:\n",
        "        train_li.append(0)\n",
        "df['Binary']=train_li\n",
        "df.head()"
      ],
      "id": "b112dd30",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  Binary\n",
              "0  One of the other reviewers has mentioned that ...  positive       1\n",
              "1  A wonderful little production. <br /><br />The...  positive       1\n",
              "2  I thought this was a wonderful way to spend ti...  positive       1\n",
              "3  Basically there's a family where a little boy ...  negative       0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive       1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e67bfa4e"
      },
      "source": [
        "Data Preprocessing"
      ],
      "id": "e67bfa4e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "390f98f9"
      },
      "source": [
        "#Removes Punctuations\n",
        "def remove_punctuations(data):\n",
        "    punct_tag=re.compile(r'[^\\w\\s]')\n",
        "    data=punct_tag.sub(r'',data)\n",
        "    return data\n",
        "\n",
        "#Removes HTML syntaxes\n",
        "def remove_html(data):\n",
        "    html_tag=re.compile(r'<.*?>')\n",
        "    data=html_tag.sub(r'',data)\n",
        "    return data\n",
        "\n",
        "#Removes URL data\n",
        "def remove_url(data):\n",
        "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
        "    data=url_clean.sub(r'',data)\n",
        "    return data\n",
        "\n",
        "#Removes Emojis\n",
        "def remove_emoji(data):\n",
        "    emoji_clean= re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    data=emoji_clean.sub(r'',data)\n",
        "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
        "    data=url_clean.sub(r'',data)\n",
        "    return data"
      ],
      "id": "390f98f9",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40a11536"
      },
      "source": [
        "#Lemmatize the corpus for root words\n",
        "def lemma_traincorpus(data):\n",
        "    lemmatizer=WordNetLemmatizer()\n",
        "    out_data=\"\"\n",
        "    for words in data:\n",
        "        out_data+= lemmatizer.lemmatize(words)\n",
        "    return out_data"
      ],
      "id": "40a11536",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3becd169"
      },
      "source": [
        "df['review']=df['review'].apply(lambda z: remove_punctuations(z))\n",
        "df['review']=df['review'].apply(lambda z: remove_html(z))\n",
        "df['review']=df['review'].apply(lambda z: remove_url(z))\n",
        "df['review']=df['review'].apply(lambda z: remove_emoji(z))\n",
        "count_good=df[df['sentiment']=='positive']\n",
        "count_bad=df[df['sentiment']=='negative']\n",
        "df['review']=df['review'].apply(lambda z: lemma_traincorpus(z))"
      ],
      "id": "3becd169",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f24737d"
      },
      "source": [
        "##### TFIDF Vectorizer"
      ],
      "id": "5f24737d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIMt8Pen0l8H"
      },
      "source": [
        "TFIDF vectorization is non semantic frequency based algorithm which uses a logarithmic distribution over document frequencies to embed vectors based on normalized frequency of occurence of words in the corpus."
      ],
      "id": "WIMt8Pen0l8H"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15a3ff6b"
      },
      "source": [
        "#TFIDF Vectorize the Data\n",
        "\n",
        "def tfidf(data):\n",
        "    tfidfv = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "    fit_data_tfidf=tfidfv.fit_transform(data)\n",
        "    return fit_data_tfidf\n",
        "\n",
        "train_set=tfidf(df['review'])"
      ],
      "id": "15a3ff6b",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5668e6a",
        "outputId": "91d07753-6051-4b8b-9ed2-9a5d28f1d5c9"
      },
      "source": [
        "#Train Test Split\n",
        "\n",
        "train_y=df['sentiment']\n",
        "train_x,test_x,train_y,test_y=train_test_split(train_set,train_y,test_size=0.2,random_state=42)\n",
        "train_x.shape,train_y.shape,test_x.shape,test_y.shape"
      ],
      "id": "b5668e6a",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 150000), (40000,), (10000, 150000), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a1c457",
        "outputId": "9c447a9e-be7b-4d97-9e29-850b0f90eeb7"
      },
      "source": [
        "#Applying Logistic Regression on split tfidf baseline\n",
        "model=LogisticRegression()\n",
        "model.fit(train_x,train_y)\n",
        "pred=model.predict(test_x)\n",
        "print(\"Evaluate confusion matrix for LR\")\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(f\"Accuracy Score for LR with C=1.0  ={accuracy_score(test_y,pred)}\")"
      ],
      "id": "d5a1c457",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate confusion matrix for LR\n",
            "[[4367  594]\n",
            " [ 419 4620]]\n",
            "Accuracy Score for LR with C=1.0  =0.8987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0154120c"
      },
      "source": [
        "models=[]\n",
        "models.append(('LogisticRregression',LogisticRegression(C=1.0,penalty='l2')))\n",
        "models.append(('KNearestNeighbors',KNeighborsClassifier()))\n",
        "models.append(('DecisionTree',DecisionTreeClassifier(criterion='entropy')))"
      ],
      "id": "0154120c",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2d50d1b",
        "outputId": "dc15035b-3a9b-406b-b180-8f43d20d5b46"
      },
      "source": [
        "scoring='accuracy'\n",
        "print(\"Statistical Model TFIDF- Baseline Evaluation\")\n",
        "for name,model in models:\n",
        "    kfold=KFold(n_splits=10)\n",
        "    results=cross_val_score(model,train_x,train_y,cv=kfold)\n",
        "    predictions=cross_val_predict(model,test_x,test_y)\n",
        "    accuracy = accuracy_score(predictions,test_y)\n",
        "    print(\"=======================\")\n",
        "    print(\"Classifiers: \",name, \"Has a training score of\", round(results.mean(), 2) * 100, \"% accuracy score\")\n",
        "    print(\"Classifiers: \",name, \"Has a testing score of\", round(accuracy, 2) * 100, \"% accuracy score\")"
      ],
      "id": "c2d50d1b",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Model TFIDF- Baseline Evaluation\n",
            "=======================\n",
            "Classifiers:  LogisticRregression Has a training score of 89.0 % accuracy score\n",
            "Classifiers:  LogisticRregression Has a testing score of 87.0 % accuracy score\n",
            "=======================\n",
            "Classifiers:  KNearestNeighbors Has a training score of 78.0 % accuracy score\n",
            "Classifiers:  KNearestNeighbors Has a testing score of 74.0 % accuracy score\n",
            "=======================\n",
            "Classifiers:  DecisionTree Has a training score of 72.0 % accuracy score\n",
            "Classifiers:  DecisionTree Has a testing score of 71.0 % accuracy score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08xanYjWz2H_"
      },
      "source": [
        "From the Kfold cross validation results we can infer logistic regression model suits best for the TFIDF vectorized data. "
      ],
      "id": "08xanYjWz2H_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4b7f79f"
      },
      "source": [
        "##### Count Vectorizer"
      ],
      "id": "c4b7f79f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQwaeCam4QJ8"
      },
      "source": [
        "This is a simpler vectorization technique which relies on frequency of occurence of a particular term in a document or corpus."
      ],
      "id": "xQwaeCam4QJ8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "436c089d"
      },
      "source": [
        "#count Vectorize the Data\n",
        "\n",
        "def count_vec(data):\n",
        "    count_v = CountVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "    fit_data_count_v=count_v.fit_transform(data)\n",
        "    return fit_data_count_v\n",
        "\n",
        "train_set=count_vec(df['review'])"
      ],
      "id": "436c089d",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b263b34f",
        "outputId": "702b8586-836f-4942-ca80-026cce082ca0"
      },
      "source": [
        "#Train Test Split\n",
        "\n",
        "train_y=df['sentiment']\n",
        "train_x,test_x,train_y,test_y=train_test_split(train_set,train_y,test_size=0.2,random_state=42)\n",
        "train_x.shape,train_y.shape,test_x.shape,test_y.shape"
      ],
      "id": "b263b34f",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 150000), (40000,), (10000, 150000), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecc79d63",
        "outputId": "b7652b61-abc1-4aad-bb5c-399831817dd0"
      },
      "source": [
        "#Applying Logistic Regression on split \n",
        "model=LogisticRegression()\n",
        "model.fit(train_x,train_y)\n",
        "pred=model.predict(test_x)\n",
        "print(\"Evaluate confusion matrix for LR\")\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(f\"Accuracy Score for LR with C=1.0  ={accuracy_score(test_y,pred)}\")"
      ],
      "id": "ecc79d63",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate confusion matrix for LR\n",
            "[[4402  559]\n",
            " [ 482 4557]]\n",
            "Accuracy Score for LR with C=1.0  =0.8959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfdf0436",
        "outputId": "b73d6414-6455-4b8c-c351-88668817529a"
      },
      "source": [
        "#Applying Linear SVC on split\n",
        "model = LinearSVC(C=0.5, random_state=42)\n",
        "model.fit(train_x,train_y)\n",
        "pred=model.predict(test_x)\n",
        "print(\"Evaluate confusion matrix for SVC\")\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(f\"Accuracy Score for SVC with C=0.5  ={accuracy_score(test_y,pred)}\")"
      ],
      "id": "dfdf0436",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate confusion matrix for SVC\n",
            "[[4389  572]\n",
            " [ 552 4487]]\n",
            "Accuracy Score for SVC with C=0.5  =0.8876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da449886"
      },
      "source": [
        "Another variation of CountVectorizer with binary=True and in that case all zero entries will have 1"
      ],
      "id": "da449886"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c3d5fef"
      },
      "source": [
        "def count_vec(dat):\n",
        "    count_v = CountVectorizer(stop_words='english', ngram_range=(1, 3), binary=True, lowercase=True, max_features=150000)\n",
        "    fit_data_count_v=count_v.fit_transform(dat)\n",
        "    return fit_data_count_v\n",
        "\n",
        "train_set=count_vec(df['review'])"
      ],
      "id": "0c3d5fef",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d12b2fd7",
        "outputId": "caa59f81-b755-4eac-bdc7-67d61233b592"
      },
      "source": [
        "#Train Test Split\n",
        "\n",
        "train_y=df['sentiment']\n",
        "train_x,test_x,train_y,test_y=train_test_split(train_set,train_y,test_size=0.2,random_state=42)\n",
        "train_x.shape,train_y.shape,test_x.shape,test_y.shape"
      ],
      "id": "d12b2fd7",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 150000), (40000,), (10000, 150000), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bb9eb1f",
        "outputId": "0fa0f7d1-0e07-4775-b0e8-756dfdde6277"
      },
      "source": [
        "#Applying Logistic Regression on split \n",
        "model=LogisticRegression()\n",
        "model.fit(train_x,train_y)\n",
        "pred=model.predict(test_x)\n",
        "print(\"Evaluate confusion matrix for LR\")\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(f\"Accuracy Score for LR ={accuracy_score(test_y,pred)}\")"
      ],
      "id": "0bb9eb1f",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate confusion matrix for LR\n",
            "[[4422  539]\n",
            " [ 507 4532]]\n",
            "Accuracy Score for LR =0.8954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ed1d4e4",
        "outputId": "d33333b8-7f0d-4e74-d4e2-e133e60cef99"
      },
      "source": [
        "#Applying Linear SVC on split\n",
        "model = LinearSVC(C=0.5, random_state=42)\n",
        "model.fit(train_x,train_y)\n",
        "pred=model.predict(test_x)\n",
        "print(\"Evaluate confusion matrix for SVC\")\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(f\"Accuracy Score for SVC with C=0.5  ={accuracy_score(test_y,pred)}\")"
      ],
      "id": "9ed1d4e4",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate confusion matrix for SVC\n",
            "[[4401  560]\n",
            " [ 567 4472]]\n",
            "Accuracy Score for SVC with C=0.5  =0.8873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3L32fJO3Klj"
      },
      "source": [
        "Not much difference between counter vectorizer and TFIDF vectorizer, both provided similar results,"
      ],
      "id": "d3L32fJO3Klj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a4772ac"
      },
      "source": [
        "##### LSTM Model"
      ],
      "id": "9a4772ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWNPgmCz6fkh"
      },
      "source": [
        "We can apply Recurrent Neural Networks like LSTM to perform sentiment analysis and we have a different vectorization technique called Word Embeddings.\n",
        "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, we do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
        "Reference: https://www.tensorflow.org/tutorials/text/word_embeddings"
      ],
      "id": "xWNPgmCz6fkh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d30dd1a3"
      },
      "source": [
        "max_features = 20000\n",
        "maxlen = 200\n",
        "tokenizer = Tokenizer(num_words=max_features)"
      ],
      "id": "d30dd1a3",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4f590e",
        "outputId": "927dcd21-3d76-4b97-a2a5-43f190ecc23a"
      },
      "source": [
        "#Train Test Split\n",
        "train_set = pd.DataFrame(df['review'])\n",
        "train_y=df['Binary']\n",
        "train_x,test_x,train_y,test_y=train_test_split(train_set,train_y,test_size=0.2,random_state=42)\n",
        "train_x.shape,train_y.shape,test_x.shape,test_y.shape"
      ],
      "id": "ba4f590e",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 1), (40000,), (10000, 1), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1dc1d5a"
      },
      "source": [
        "tokenizer.fit_on_texts(train_x['review'])\n",
        "X_train_token = tokenizer.texts_to_sequences(train_x['review'])\n",
        "\n",
        "tokenizer.fit_on_texts(test_x['review'])\n",
        "X_test_token = tokenizer.texts_to_sequences(test_x['review'])"
      ],
      "id": "b1dc1d5a",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf4f3218",
        "outputId": "f78fd8c5-e886-499d-8887-abbda1095887"
      },
      "source": [
        "X_train = pad_sequences(X_train_token, maxlen=maxlen, padding='post')\n",
        "X_test  = pad_sequences(X_test_token, maxlen=maxlen, padding='post')\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "id": "bf4f3218",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 200) (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03e1924c"
      },
      "source": [
        "y_train = train_y.copy()\n",
        "y_test  = test_y.copy()"
      ],
      "id": "03e1924c",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d079ada5"
      },
      "source": [
        "model = Sequential([Embedding(max_features, 64, mask_zero=True),\n",
        "                    Bidirectional(LSTM(64, dropout=0.2)),\n",
        "                    Dense(64, activation='sigmoid'),\n",
        "                    Dense(1)])"
      ],
      "id": "d079ada5",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f6c50da"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "id": "2f6c50da",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ee71c3a",
        "outputId": "9bc8765c-b31f-4844-f412-6c403a1f1dc0"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=50,\n",
        "                    epochs=3,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "id": "5ee71c3a",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "800/800 [==============================] - 286s 350ms/step - loss: 7.6974 - accuracy: 0.5010 - val_loss: 7.7726 - val_accuracy: 0.4961\n",
            "Epoch 2/3\n",
            "800/800 [==============================] - 274s 342ms/step - loss: 7.6975 - accuracy: 0.5010 - val_loss: 7.7726 - val_accuracy: 0.4961\n",
            "Epoch 3/3\n",
            "800/800 [==============================] - 277s 346ms/step - loss: 7.6974 - accuracy: 0.5010 - val_loss: 7.7726 - val_accuracy: 0.4961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbc53721",
        "outputId": "8c529e11-6e43-4f25-bfd1-f3cacb3a0509"
      },
      "source": [
        "history.history"
      ],
      "id": "fbc53721",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5009750127792358, 0.5009750127792358, 0.5009750127792358],\n",
              " 'loss': [7.697445392608643, 7.697450160980225, 7.697446823120117],\n",
              " 'val_accuracy': [0.4961000084877014, 0.4961000084877014, 0.4961000084877014],\n",
              " 'val_loss': [7.77263069152832, 7.77263069152832, 7.77263069152832]}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ea3ddd"
      },
      "source": [
        "We can conclude that Bi-directional LSTM takes more time to train and is performing poorly compared to TF-IDF vectorization, Counter Vectorization."
      ],
      "id": "e8ea3ddd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8800f000"
      },
      "source": [
        "##### Word2Vec (CBOW)"
      ],
      "id": "8800f000"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg0X5OJG7nAn"
      },
      "source": [
        "Word2Vec is one of the traditional algorithms which was emphasized based on Heirarchical Softmax as well as with simplistic RNNs. Gensim provides a great way to use and start with Word2Vec. The Word2Vec algorithm builds by using the Skipgram model as well as the Common Bag of Words Model."
      ],
      "id": "Pg0X5OJG7nAn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2d2698"
      },
      "source": [
        "# Converting input dataframe into list\n",
        "check_df=list(df['review'].str.split())"
      ],
      "id": "6e2d2698",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "915a1037"
      },
      "source": [
        "# Creating CBOW model\n",
        "w2v_model=Word2Vec(check_df,min_count=1)"
      ],
      "id": "915a1037",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e23c4f5",
        "outputId": "7cdf6992-54f3-4f9b-a0de-93c112f2ec24"
      },
      "source": [
        "#Label Encode the labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_y= LabelEncoder()\n",
        "labels=label_y.fit_transform(df['sentiment'])\n",
        "labels"
      ],
      "id": "3e23c4f5",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "659a4664",
        "outputId": "6c234653-7771-49d9-8e3f-4ccf3481782b"
      },
      "source": [
        "w2v_model.wv.most_similar('good')"
      ],
      "id": "659a4664",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('decent', 0.7890726327896118),\n",
              " ('great', 0.7716896533966064),\n",
              " ('bad', 0.7483441829681396),\n",
              " ('nice', 0.7346286177635193),\n",
              " ('cool', 0.7161738872528076),\n",
              " ('fine', 0.708539605140686),\n",
              " ('solid', 0.6666469573974609),\n",
              " ('fantastic', 0.6275328397750854),\n",
              " ('mediocre', 0.6257743835449219),\n",
              " ('poor', 0.6251050233840942)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2c8c27",
        "outputId": "ef24b2d1-a0a9-4ef7-ef85-258bae348233"
      },
      "source": [
        "#Word2Vec model returns the similar words for a given word\n",
        "w2v_model.wv.most_similar('interesting', topn=10)"
      ],
      "id": "4e2c8c27",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('intriguing', 0.8061264157295227),\n",
              " ('exciting', 0.7619497776031494),\n",
              " ('important', 0.7323001623153687),\n",
              " ('entertaining', 0.7215830087661743),\n",
              " ('engaging', 0.708055853843689),\n",
              " ('unusual', 0.7034302949905396),\n",
              " ('enjoyable', 0.6961750984191895),\n",
              " ('fascinating', 0.6960465908050537),\n",
              " ('amusing', 0.687725305557251),\n",
              " ('odd', 0.686927318572998)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "11b42923",
        "outputId": "ee4d486b-0c9d-494a-e201-678c8195906d"
      },
      "source": [
        "w2v_model.wv.doesnt_match([\"king\", \"george\",\"stephen\",\"truck\"])"
      ],
      "id": "11b42923",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'truck'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6pEM1F67sRm"
      },
      "source": [
        "Since Word2Vec creates vector embeddings for individual words in a corpus by transforming them to a manifold, we need effective document /sentence vectors from these individual vectorized words."
      ],
      "id": "E6pEM1F67sRm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c96BMvt9hSOg",
        "outputId": "8c65439f-e0c4-4ff2-a010-7fbc08c74f60"
      },
      "source": [
        "#Convert word vectors to sentence vectors/sentence vectors and apply mean pooling\n",
        "\n",
        "def convert_sentence(data):\n",
        "    vocab=[w for w in data if w in w2v_model.wv.vocab]\n",
        "    avg_pool=np.mean(w2v_model[vocab],axis=0)\n",
        "    return avg_pool\n",
        "\n",
        "df['Vectorized_Reviews']=df['review'].apply(convert_sentence)\n",
        "\n",
        "#Split the dataset into training and testing sets\n",
        "train_y=df['sentiment']\n",
        "train_x,test_x,train_y,test_y=train_test_split(df['Vectorized_Reviews'],train_y,test_size=0.2,random_state=42)\n",
        "train_x.shape,train_y.shape,test_x.shape,test_y.shape"
      ],
      "id": "c96BMvt9hSOg",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000,), (40000,), (10000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9hrCSFdjQY2"
      },
      "source": [
        "test_x=list(test_x)\n",
        "train_x=list(train_x)"
      ],
      "id": "w9hrCSFdjQY2",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glUou0eejTqh"
      },
      "source": [
        "models=[]\n",
        "models.append(('LogisticRregression',LogisticRegression(C=1.0,penalty='l2')))\n",
        "models.append(('KNearestNeighbors',KNeighborsClassifier()))\n",
        "models.append(('LinearSVC',LinearSVC(C=0.5)))"
      ],
      "id": "glUou0eejTqh",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX4y7Sf-jsxL",
        "outputId": "96b31eeb-86b6-4c83-9529-e834d3ac0ef8"
      },
      "source": [
        "scoring='accuracy'\n",
        "print(\"Statistical Model Word2Vec- Baseline Evaluation\")\n",
        "for name,model in models:\n",
        "    kfold=KFold(n_splits=10)\n",
        "    results=cross_val_score(model,train_x,train_y,cv=kfold)\n",
        "    predictions=cross_val_predict(model,test_x,test_y)\n",
        "    accuracy = accuracy_score(predictions,test_y)\n",
        "    print(\"=======================\")\n",
        "    print(\"Classifiers: \",name, \"Has a training score of\", round(results.mean(), 2) * 100, \"% accuracy score\")\n",
        "    print(\"Classifiers: \",name, \"Has a testing score of\", round(accuracy, 2) * 100, \"% accuracy score\")"
      ],
      "id": "OX4y7Sf-jsxL",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Model Word2Vec- Baseline Evaluation\n",
            "=======================\n",
            "Classifiers:  LogisticRregression Has a training score of 62.0 % accuracy score\n",
            "Classifiers:  LogisticRregression Has a testing score of 60.0 % accuracy score\n",
            "=======================\n",
            "Classifiers:  KNearestNeighbors Has a training score of 54.0 % accuracy score\n",
            "Classifiers:  KNearestNeighbors Has a testing score of 55.00000000000001 % accuracy score\n",
            "=======================\n",
            "Classifiers:  LinearSVC Has a training score of 63.0 % accuracy score\n",
            "Classifiers:  LinearSVC Has a testing score of 61.0 % accuracy score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWrHfjk5pWgn"
      },
      "source": [
        "train_x = np.array(train_x)\n",
        "test_x = np.array(test_x)"
      ],
      "id": "DWrHfjk5pWgn",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-IMF0y0oxnx"
      },
      "source": [
        "#Evaluating XGBoost on the dataset\n",
        "from xgboost import XGBClassifier \n",
        "model_xgb= XGBClassifier()\n",
        "model_xgb.fit(train_x,train_y)\n",
        "y_pred_xgb=model_xgb.predict(test_x)"
      ],
      "id": "D-IMF0y0oxnx",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAFt_DnOqJRi",
        "outputId": "5016a10c-8df0-4880-b965-0f67c08a1da9"
      },
      "source": [
        "print(\"Accuracy score: \",(accuracy_score(test_y,y_pred_xgb)))\n",
        "print(\"Confusion matrix\")\n",
        "print(confusion_matrix(test_y,y_pred_xgb))"
      ],
      "id": "BAFt_DnOqJRi",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.6058\n",
            "Confusion matrix\n",
            "[[2996 1965]\n",
            " [1977 3062]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_14Snmh-Mem"
      },
      "source": [
        "When trained with multiple models, the best results was from Count vectorization with 89 testing scores repectively. Since the data had binary targets and the best results was from logistic regression and LinearSVC we can infer the data was linearly distributed."
      ],
      "id": "q_14Snmh-Mem"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrfGG1DzBbKh"
      },
      "source": [
        "Final Results:\n",
        "- TFIDF Vectorization:\n",
        "    - Logistic Regression: 87% \n",
        "    - KNearestNeighbour  : 74%\n",
        "    - Decision Tree      : 71%\n",
        "- Count Vectorization: \n",
        "    - Logistic Regression: 89% \n",
        "    - LinearSVC          : 88%\n",
        "- Genism Word2Vec(CBOW):\n",
        "    - Logistic Regression: 60% \n",
        "    - KNearestNeighbour  : 55%\n",
        "    - LinearSVC          : 61%\n",
        "    - XGBoost            : 60%\n",
        "- Bidrectional LSTM: Mean Accuracy of 50% "
      ],
      "id": "yrfGG1DzBbKh"
    }
  ]
}