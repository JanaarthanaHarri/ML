{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHVZdC-WGHLL"
   },
   "source": [
    "### What are the main motivations for reducing a dataset’s dimensionality? \n",
    "\n",
    "+ Speed up subsequent training algorithm\n",
    "+ Visualize the data and gain insights on the most important features\n",
    "+ Save space (compression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzK3mXE4GHLY"
   },
   "source": [
    "### What are the main drawbacks? \n",
    "\n",
    "+ Some info is lost, possibly degrading performance\n",
    "+ Computationally intensive\n",
    "+ Adds some complexity to your ML pipelines\n",
    "+ Transformed features can be hard to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDF-7N6pG4-O"
   },
   "source": [
    "### What are other applications of PCA (other than visualizing data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHFM1_FFG4uZ"
   },
   "source": [
    "- data compression\n",
    "- image processing \n",
    "- exploratory data analysis \n",
    "- pattern recognition \n",
    "- time series prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSDKxE7HG_Z5"
   },
   "source": [
    "### What are the limitations of PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTWnu591G4SF"
   },
   "source": [
    " - It may lead to some amount of data loss.\n",
    " - PCA tends to find linear correlations between variables, which is sometimes undesirable.\n",
    " - PCA fails in cases where mean and covariance are not enough to define datasets.\n",
    " - We may not know how many principal components to keep- in practice, some thumb rules are applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS_QWLDuGHLZ"
   },
   "source": [
    "### Load the MNIST dataset (given below) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_4apQojGHLa"
   },
   "source": [
    "### Split it into a training set and a test set\n",
    "### Take the first 60,000 instances for training, and the remaining 10,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K6IVn2FlGHLa"
   },
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tfes2owSGHLa"
   },
   "source": [
    "### Train a Random Forest classifier on the dataset and time how long it takes, \n",
    "### then evaluate the resulting model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-637frfOGHLa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train RandomForest model: 41.1946496963501\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "start_time = time.time()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "print(\"Time taken to train RandomForest model: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.97      0.96      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.96      0.95      0.96       974\n",
      "           9       0.96      0.95      0.95      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "Confusion Report\n",
      "[[ 971    1    0    0    0    4    2    1    1    0]\n",
      " [   0 1124    2    3    0    2    2    0    2    0]\n",
      " [   7    0  998    5    3    0    3   10    6    0]\n",
      " [   0    0    9  977    0    5    0    9    8    2]\n",
      " [   1    0    0    0  956    0    6    0    3   16]\n",
      " [   2    0    1   14    3  858    4    2    6    2]\n",
      " [   5    3    0    0    2    4  941    0    3    0]\n",
      " [   0    6   19    1    1    1    0  986    2   12]\n",
      " [   5    0    2    8    5    6    4    3  930   11]\n",
      " [   6    5    2   11   10    3    1    5    6  960]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred=rf.predict(X_test)\n",
    "\n",
    "print (\"Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print (\"Confusion Report\")\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DyypiqOGHLb"
   },
   "source": [
    "### Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "--8uRdpBGHLb"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA(n_components=0.95)\n",
    "\n",
    "X_data=pca.fit_transform(X)\n",
    "X_pca=pd.DataFrame(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 154)\n"
     ]
    }
   ],
   "source": [
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvpNwaKQGHLb"
   },
   "source": [
    "### Train a new Random Forest classifier on the reduced dataset and see how long it takes.\n",
    "### Was training much faster? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = X_pca[:60000]\n",
    "X_test_pca = X_pca[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iSmomntyGHLb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train RandomForest model with PCA: 80.49040150642395\n"
     ]
    }
   ],
   "source": [
    "rf_pca=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_pca.fit(X_train_pca,y_train)\n",
    "\n",
    "print(\"Time taken to train RandomForest model with PCA: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1u9d4FpGHLc"
   },
   "source": [
    "### Next evaluate the classifier on the test set: how does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IEd77HLFGHLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with PCA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.94      0.94      0.94      1032\n",
      "           3       0.93      0.94      0.94      1010\n",
      "           4       0.94      0.96      0.95       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.93      0.91      0.92       974\n",
      "           9       0.95      0.92      0.93      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Confusion Report with PCA\n",
      "[[ 965    0    2    1    0    4    5    1    2    0]\n",
      " [   0 1118    5    3    0    0    3    0    6    0]\n",
      " [  12    0  967   10    6    2    2    8   24    1]\n",
      " [   1    0   12  954    1   11    0    9   16    6]\n",
      " [   1    2    8    0  942    2    6    1    3   17]\n",
      " [   7    0    4   21    5  828   11    2    8    6]\n",
      " [  10    4    1    0    4    5  933    0    1    0]\n",
      " [   2    7   17    4    5    0    0  977    1   15]\n",
      " [   8    0   13   18   10   19    4    8  885    9]\n",
      " [   9    6    2   13   27    4    2   12    6  928]]\n"
     ]
    }
   ],
   "source": [
    "pred_pca=rf_pca.predict(X_test_pca)\n",
    "\n",
    "print (\"Classification Report with PCA\")\n",
    "print(classification_report(y_test, pred_pca))\n",
    "\n",
    "print (\"Confusion Report with PCA\")\n",
    "print(confusion_matrix(y_test, pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- Time taken without PCA = 41 seconds\n",
    "- Time taken with PCA = 81 seconds\n",
    "- Accuracy without PCA = 0.97\n",
    "- Accuracy wiht PCA = 0.95\n",
    "- Random Forest model without PCA performed better but with PCA the size has been drastically reduced to save more memory. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW 10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
